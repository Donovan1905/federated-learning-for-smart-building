{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, MaxPool1D\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras import Sequential\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import hickle as hkl\n",
    "import copy\n",
    "from scipy.spatial import distance_matrix\n",
    "import sys\n",
    "import random\n",
    "import math"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calculating dataset size weight per client\n",
    "local_coeffs = {}\n",
    "for i in range(0,clientCount):\n",
    "    local_coeffs[i] = np.float32(len(clientLabelTrain[i])) / np.float32(len(centralTrainLabel))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# initializing client model\n",
    "local_nets = {}\n",
    "local_histories = {}\n",
    "\n",
    "for i in range(0,clientCount):\n",
    "    local_nets[i] = create_keras_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# initialization of client distance (for distance measurement)\n",
    "clientEuclidDistMean = {}\n",
    "clientEuclidDistStd = {}\n",
    "for i in range(clientCount):\n",
    "    clientEuclidDistMean[i] = np.zeros(communicationRound)\n",
    "    clientEuclidDistStd[i] = np.zeros(communicationRound)\n",
    "\n",
    "# Federated learning training\n",
    "for roundNum in range(0, communicationRound):\n",
    "    start_time = time.time()\n",
    "    trainAcc = []\n",
    "    trainLoss = []\n",
    "\n",
    "    testAcc = []\n",
    "    testLoss = []\n",
    "\n",
    "    clientTrainAcc = []\n",
    "    clientTrainLoss = []\n",
    "\n",
    "    clientTestAcc = []\n",
    "    clientTestLoss = []\n",
    "\n",
    "    local_weights = {}\n",
    "\n",
    "    if (asyncTest):\n",
    "        if (roundNum in roundEnd):\n",
    "            for i in range(clientDeleteCount):\n",
    "                if (len(trainPool) != 0):\n",
    "                    selection = random.choice(list(enumerate(trainPool)))\n",
    "                    del trainPool[selection[0]]\n",
    "                    idlePool.append(selection[1])\n",
    "            for i in range(clientAddCount):\n",
    "                if (len(idlePool) != 0):\n",
    "                    selection = random.choice(list(enumerate(idlePool)))\n",
    "                    del idlePool[selection[0]]\n",
    "                    trainPool.append(selection[1])\n",
    "\n",
    "        participantDataInstance = []\n",
    "        for index, i in enumerate(trainPool):\n",
    "            participantDataInstance.append(clientLabelTrain[i])\n",
    "        participantDataInstance = (np.hstack((participantDataInstance)))\n",
    "        local_coeffs = {}\n",
    "        for index, i in enumerate(trainPool):\n",
    "            local_coeffs[i] = np.float32(len(clientLabelTrain[i])) / np.float32(len(participantDataInstance))\n",
    "    for index, i in enumerate(trainPool):\n",
    "        print(\"Status: Round #\" + str(roundNum) + \" Client #\" + str(i))\n",
    "\n",
    "        if (algorithm == \"FEDPER\"):\n",
    "            local_nets[i].load_weights(filepath + 'serverWeights.h5', by_name=True)\n",
    "        else:\n",
    "            local_nets[i].load_weights(filepath + 'serverWeights.h5', by_name=False)\n",
    "        if (optimizer == \"SGD\"):\n",
    "            local_nets[i].compile(optimizer=SGD(learning_rate=learningRate), loss='sparse_categorical_crossentropy',\n",
    "                                  metrics=['acc'])\n",
    "        else:\n",
    "            local_nets[i].compile(optimizer=Adam(learning_rate=learningRate), loss='sparse_categorical_crossentropy',\n",
    "                                  metrics=['acc'])\n",
    "        local_histories[i] = local_nets[i].fit(clientDataTrain[i], clientLabelTrain[i],\n",
    "                                               class_weight=local_class_weights[i], epochs=localEpoch,\n",
    "                                               verbose=showTrainVerbose)\n",
    "\n",
    "        local_weights[i] = local_nets[i].get_weights()\n",
    "        trainAcc.append(local_histories[i].history['acc'])\n",
    "        trainLoss.append(local_histories[i].history['loss'])\n",
    "\n",
    "        #         testing againts their own testset\n",
    "        testModelMetrics = local_nets[i].evaluate(clientDataTest[i], clientLabelTest[i], verbose=showTrainVerbose)\n",
    "        testAcc.append(testModelMetrics[1])\n",
    "        testLoss.append(testModelMetrics[0])\n",
    "\n",
    "        if (ClientAllTest == True):\n",
    "            #           testing againts their all testset\n",
    "            clientTrainModelMetrics = local_nets[i].evaluate(centralTrainData, centralTrainLabel,\n",
    "                                                             verbose=showTrainVerbose)\n",
    "            clientTrainAcc.append(clientTrainModelMetrics[1])\n",
    "            clientTrainLoss.append(clientTrainModelMetrics[0])\n",
    "\n",
    "            clientTestModelMetrics = local_nets[i].evaluate(centralTestData, centralTestLabel, verbose=showTrainVerbose)\n",
    "            clientTestAcc.append(clientTestModelMetrics[1])\n",
    "            clientTestLoss.append(clientTestModelMetrics[0])\n",
    "\n",
    "        for j in range(0, len(local_weights[i])):\n",
    "            local_weights[i][j] = local_weights[i][j] * local_coeffs[i]\n",
    "\n",
    "    if (euclid):\n",
    "        meanServerClient = []\n",
    "        stdServerClient = []\n",
    "        serverShape = np.asarray(computeWeights(serverModel.get_weights()))\n",
    "        localMeanClientLayer = []\n",
    "        localStdClientLayer = []\n",
    "        for index, clientIndex in enumerate(trainPool):\n",
    "            localMeanServerClient = []\n",
    "            localStdServerClient = []\n",
    "\n",
    "            localShape = np.asarray(computeWeights(local_nets[clientIndex].get_weights()))\n",
    "            if (algorithm != 'FEDPER'):\n",
    "                for i in range(serverShape.shape[0]):\n",
    "                    newLayerDist = np.sqrt((serverShape[i] - localShape[i]) ** 2)\n",
    "                    localMeanServerClient.append(np.mean(newLayerDist))\n",
    "                    localStdServerClient.append(np.std(newLayerDist))\n",
    "            else:\n",
    "                newLayerDist = np.sqrt((serverShape[0] - localShape[0]) ** 2)\n",
    "                localMeanServerClient.append(np.mean(newLayerDist))\n",
    "                localStdServerClient.append(np.std(newLayerDist))\n",
    "\n",
    "            localMeanClientLayer.append(localMeanServerClient)\n",
    "            localStdClientLayer.append(localStdServerClient)\n",
    "            meanServerClient.append(np.mean(localMeanServerClient))\n",
    "            stdServerClient.append(np.mean(localStdServerClient))\n",
    "            clientEuclidDistMean[clientIndex][roundNum] = np.mean(localMeanServerClient)\n",
    "            clientEuclidDistStd[clientIndex][roundNum] = np.mean(localStdServerClient)\n",
    "\n",
    "        #         15 clients\n",
    "        meanHistoryDist.append(np.asarray(meanServerClient))\n",
    "        stdHistoryDist.append(np.asarray(stdServerClient))\n",
    "\n",
    "        #         per layer distance\n",
    "        meanRoundLayerHistory.append(np.mean(localMeanClientLayer, axis=0))\n",
    "        stdRoundLayerHistory.append(np.mean(localStdClientLayer, axis=0))\n",
    "\n",
    "        #         all layer distance\n",
    "        meanRoundGeneralLayerHistory.append(np.mean(localMeanClientLayer))\n",
    "        stdRoundGeneralLayerHistory.append(np.mean(localStdClientLayer))\n",
    "\n",
    "    trainAccHistory.append(np.mean(trainAcc))\n",
    "    stdTrainAccHistory.append(np.std(trainAcc))\n",
    "    trainLossHistory.append(np.mean(trainLoss))\n",
    "    stdTrainLossHistory.append(np.std(trainLoss))\n",
    "\n",
    "    meanTestAcc = np.mean(testAcc)\n",
    "\n",
    "    testAccHistory.append(meanTestAcc)\n",
    "    stdTestAccHistory.append(np.std(testAcc))\n",
    "    testLossHistory.append(np.mean(testLoss))\n",
    "    stdTestLossHistory.append(np.std(testLoss))\n",
    "\n",
    "    if (meanTestAcc > currentAccuracy):\n",
    "        for index, net in enumerate(local_nets):\n",
    "            best_local_nets[index] = copy.copy(local_nets[index])\n",
    "        currentAccuracy = meanTestAcc\n",
    "        bestModelRound = roundNum + 1\n",
    "\n",
    "    if (ClientAllTest == True):\n",
    "        clientTrainLossHistory.append(np.mean(clientTrainLoss))\n",
    "        clientTrainAccHistory.append(np.mean(clientTrainAcc))\n",
    "        clientTestLossHistory.append(np.mean(clientTestLoss))\n",
    "        clientTestAccHistory.append(np.mean(clientTestAcc))\n",
    "\n",
    "        clientStdTrainLossHistory.append(np.std(clientTrainLoss))\n",
    "        clientStdTrainAccHistory.append(np.std(clientTrainAcc))\n",
    "        clientStdTestLossHistory.append(np.std(clientTestLoss))\n",
    "        clientStdTestAccHistory.append(np.std(clientTestAcc))\n",
    "\n",
    "    # return weights to server and sum all the model weights\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    weights = []\n",
    "    for i in local_weights:\n",
    "        weights.append(local_weights[i])\n",
    "    new_weights = list()\n",
    "    for weights_list_tuple in zip(*weights):\n",
    "        new_weights.append(np.asarray(\n",
    "            [np.array(weights_).sum(axis=0)\n",
    "             for weights_ in zip(*weights_list_tuple)]))\n",
    "    serverModel.set_weights(np.asarray(new_weights))\n",
    "    del new_weights\n",
    "    del weights\n",
    "    del weights_list_tuple\n",
    "\n",
    "    #    FedDist main implemenation begins here\n",
    "\n",
    "    for layer in range(len(layerType) - 1):\n",
    "        if (layer != len(layerType) - 1):\n",
    "            distanceMatrix = []\n",
    "            allClientWeight = {}\n",
    "            serverWeights = computeWeights(serverModel.get_weights())\n",
    "\n",
    "            for i, clientIndex in enumerate(trainPool):\n",
    "                clientWeights = computeWeights(local_nets[clientIndex].get_weights())\n",
    "                allClientWeight[clientIndex] = clientWeights\n",
    "                clientDistance = []\n",
    "                for k in range(serverWeights[layer].shape[0]):\n",
    "                    clientDistance.append(distance.euclidean(clientWeights[layer][k], serverWeights[layer][k]))\n",
    "                distanceMatrix.append(clientDistance)\n",
    "\n",
    "                del clientWeights\n",
    "                del clientDistance\n",
    "\n",
    "            distanceMatrix = np.asarray(distanceMatrix)\n",
    "            means = np.mean(distanceMatrix, axis=0)\n",
    "            stds = np.std(distanceMatrix, axis=0)\n",
    "            stdThreshold = stdCount + np.floor(roundNum / 5) * 0.25\n",
    "            threshHold = means + (stdThreshold * stds)\n",
    "\n",
    "            nextLayerOutWeights = (allClientWeight[0][layer + 1].shape[1] - 1) / allClientWeight[0][layer].shape[0]\n",
    "            newUnit = []\n",
    "            outerUnit = []\n",
    "            for i, clientIndex in enumerate(trainPool):\n",
    "                for k in range(serverWeights[layer].shape[0]):\n",
    "                    if (distanceMatrix[clientIndex][k] > threshHold[k]):\n",
    "                        newUnit.append(allClientWeight[clientIndex][layer][k])\n",
    "                        nextLayerIndexStart = int(nextLayerOutWeights * k)\n",
    "                        nextLayerIndexEnd = int(nextLayerIndexStart + nextLayerOutWeights)\n",
    "                        outerUnit.append(\n",
    "                            allClientWeight[clientIndex][layer + 1][:, nextLayerIndexStart:nextLayerIndexEnd])\n",
    "            del allClientWeight\n",
    "            del nextLayerOutWeights\n",
    "            if (len(newUnit) == 0):\n",
    "                print(\"No new unit\")\n",
    "                continue\n",
    "            else:\n",
    "                print(\"New units added :\" + str(len(newUnit)) + \" on layer : \" + str(layer))\n",
    "            serverWeights[layer] = np.vstack((serverWeights[layer], newUnit))\n",
    "            outwardsUnit = np.hstack(outerUnit)\n",
    "            bias = serverWeights[layer + 1][:, serverWeights[layer + 1].shape[1] - 1:]\n",
    "            outwardsUnit = np.hstack(\n",
    "                (serverWeights[layer + 1][:, :serverWeights[layer + 1].shape[1] - 1], outwardsUnit))\n",
    "            outwardsUnit = np.hstack((outwardsUnit, bias))\n",
    "            serverWeights[layer + 1] = outwardsUnit\n",
    "            newWeights = []\n",
    "            for layerIndex in range(len(serverWeights)):\n",
    "                sizeWithoutBias = serverWeights[layerIndex].shape[1] - 1\n",
    "                if (layerType[layerIndex] == 0):\n",
    "                    layerWeight = serverWeights[layerIndex][:, :sizeWithoutBias].T.reshape(16, 6, -1)\n",
    "                else:\n",
    "                    layerWeight = serverWeights[layerIndex][:, :sizeWithoutBias].T\n",
    "                layerBias = serverWeights[layerIndex][:, sizeWithoutBias:].ravel()\n",
    "                newWeights.append(layerWeight)\n",
    "                newWeights.append(layerBias)\n",
    "\n",
    "            del serverModel\n",
    "            tf.keras.backend.clear_session()\n",
    "            serverModel = createCNN(filter_count=newWeights[0].shape[2], dense_unit=newWeights[2].shape[1])\n",
    "            serverModel.set_weights(newWeights)\n",
    "            del serverWeights\n",
    "\n",
    "            for i in range(layer + 1):\n",
    "                serverModel.layers[layerMap[i]].trainable = False\n",
    "            local_nets = {}\n",
    "            local_weights = {}\n",
    "\n",
    "            for i, index in enumerate(trainPool):\n",
    "                tf.keras.backend.clear_session()\n",
    "                local_nets[index] = createCNN(filter_count=newWeights[0].shape[2], dense_unit=newWeights[2].shape[1])\n",
    "                local_nets[index].set_weights(newWeights)\n",
    "                for i in range(layer + 1):\n",
    "                    local_nets[index].layers[layerMap[i]].trainable = False\n",
    "                if (optimizer == \"SGD\"):\n",
    "                    local_nets[index].compile(optimizer=SGD(learning_rate=learningRate),\n",
    "                                              loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "                else:\n",
    "                    local_nets[index].compile(optimizer=Adam(learning_rate=learningRate),\n",
    "                                              loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "                local_nets[index].fit(clientDataTrain[index], clientLabelTrain[index],\n",
    "                                      class_weight=local_class_weights[index], epochs=localEpoch,\n",
    "                                      verbose=showTrainVerbose)\n",
    "\n",
    "                local_weights[index] = local_nets[index].get_weights()\n",
    "\n",
    "                for j in range(0, len(local_weights[index])):\n",
    "                    local_weights[index][j] = local_weights[index][j] * local_coeffs[index]\n",
    "\n",
    "            weights = []\n",
    "            for i in local_weights:\n",
    "                weights.append(local_weights[i])\n",
    "            new_weights = list()\n",
    "            for weights_list_tuple in zip(*weights):\n",
    "                new_weights.append(np.asarray(\n",
    "                    [np.array(weights_).sum(axis=0)\n",
    "                     for weights_ in zip(*weights_list_tuple)]))\n",
    "            serverModel.set_weights(np.asarray(new_weights))\n",
    "            del weights\n",
    "            del weights_list_tuple\n",
    "            del new_weights\n",
    "\n",
    "            for i in range(layer + 1):\n",
    "                serverModel.layers[layerMap[i]].trainable = True\n",
    "                for index, clientId in enumerate(trainPool):\n",
    "                    local_nets[clientId].layers[layerMap[i]].trainable = True\n",
    "            tf.keras.backend.clear_session()\n",
    "    serverModel.summary()\n",
    "\n",
    "    #     Main FedDist implementations end here====================\n",
    "    serverModel.save_weights(filepath + 'serverWeights.h5')\n",
    "    if (algorithm != 'FEDPER'):\n",
    "        if (optimizer == \"SGD\"):\n",
    "            serverModel.compile(optimizer=SGD(learning_rate=learningRate), loss='sparse_categorical_crossentropy',\n",
    "                                metrics=['acc'])\n",
    "        else:\n",
    "            serverModel.compile(optimizer=Adam(learning_rate=learningRate), loss='sparse_categorical_crossentropy',\n",
    "                                metrics=['acc'])\n",
    "        serverTrainMetrics = serverModel.evaluate(centralTrainData, centralTrainLabel, verbose=showTrainVerbose)\n",
    "        serverTrainLossHistory.append(serverTrainMetrics[0])\n",
    "        serverTrainAccHistory.append(serverTrainMetrics[1])\n",
    "\n",
    "        serverTestMetrics = serverModel.evaluate(centralTestData, centralTestLabel, verbose=showTrainVerbose)\n",
    "        serverTestLossHistory.append(serverTestMetrics[0])\n",
    "        serverTestAccHistory.append(serverTestMetrics[1])\n",
    "        if (serverTestMetrics[1] > serverCurrentAccuracy):\n",
    "            serverCurrentAccuracy = serverTestMetrics[1]\n",
    "            serverbestModelRound = roundNum + 1\n",
    "            bestServerModel = copy.copy(serverModel)\n",
    "        del serverTestMetrics\n",
    "        del serverTrainMetrics\n",
    "    tf.keras.backend.clear_session()\n",
    "endTime = time.time() - start_time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}